{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "batch_size = 1\n",
        "seq_len = 5\n",
        "INPUT_DIM = 10\n",
        "HIDDEN_DIM = 20\n",
        "SUM_DIM = INPUT_DIM + HIDDEN_DIM\n",
        "x = torch.randn(batch_size, seq_len, INPUT_DIM)\n",
        "h_0 = torch.zeros((batch_size, HIDDEN_DIM))\n",
        "c_0 = torch.zeros((batch_size, HIDDEN_DIM))\n",
        "\n",
        "'''\n",
        "initialize the weights of each layer\n",
        "'''\n",
        "Wf = torch.randn(HIDDEN_DIM,SUM_DIM)\n",
        "Wi = torch.randn(HIDDEN_DIM,SUM_DIM)\n",
        "Wo = torch.randn(HIDDEN_DIM,SUM_DIM)\n",
        "Wc = torch.randn(HIDDEN_DIM,SUM_DIM)\n",
        "\n",
        "bf = torch.randn(HIDDEN_DIM, batch_size)\n",
        "bi = torch.randn(HIDDEN_DIM, batch_size)\n",
        "bo = torch.randn(HIDDEN_DIM, batch_size)\n",
        "bc = torch.randn(HIDDEN_DIM, batch_size)\n",
        "\n",
        "\n",
        "x_0 = x[:, 0, :].reshape(batch_size, -1)\n",
        "combined = torch.concat([h_0, x_0],dim=1)\n",
        "\n",
        "f_t = sigmoid((Wf @ combined.T) + bf)\n",
        "i_t = sigmoid((Wi @ combined.T) + bi)\n",
        "o_t = sigmoid((Wo @ combined.T) + bo)\n",
        "c_hat_t = tanh((Wc @ combined.T) + bc)\n",
        "\n",
        "f_t = f_t.permute(1,0)\n",
        "i_t = i_t.permute(1,0)\n",
        "o_t = o_t.permute(1,0)\n",
        "c_hat_t = c_hat_t.permute(1,0)\n",
        "\n",
        "c_t = f_t * c_0 + i_t * c_hat_t # next cell state\n",
        "h_t = o_t * tanh(c_t) # next hidden state"
      ],
      "metadata": {
        "id": "uVtKSg42Dm0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d63IpUkUgN-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Activations(object):\n",
        "  def sigmoid(x):\n",
        "      return 1 / (1 + np.exp(-x))\n",
        "\n",
        "  def tanh(x):\n",
        "      return np.tanh(x)\n",
        "\n",
        "class LSTM:\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Initialize weights\n",
        "        self.Wf = torch.randn(self.hidden_dim, self.hidden_dim + self.input_dim)\n",
        "        self.Wi = torch.randn(self.hidden_dim, self.hidden_dim + self.input_dim)\n",
        "        self.Wo = torch.randn(self.hidden_dim, self.hidden_dim + self.input_dim)\n",
        "        self.Wc = torch.randn(self.hidden_dim, self.hidden_dim + self.input_dim)\n",
        "\n",
        "        # Initialize bias\n",
        "        self.bf = torch.zeros((self.hidden_dim, 1))\n",
        "        self.bi = torch.zeros((self.hidden_dim, 1))\n",
        "        self.bo = torch.zeros((self.hidden_dim, 1))\n",
        "        self.bc = torch.zeros((self.hidden_dim, 1))\n",
        "\n",
        "    def forward(self, x, h_t, c_t):\n",
        "        batch_size, sequence_len, _ = x.shape\n",
        "        h_ts = []\n",
        "        for t in range(sequence_len):\n",
        "            x_t = x[:, t, :].reshape(batch_size, -1)\n",
        "            combined = torch.concat([h_t, x_t],dim=1)\n",
        "\n",
        "            f_t = Activations.sigmoid((self.Wf @ combined.T + self.bf))\n",
        "            i_t = Activations.sigmoid((self.Wi @ combined.T + self.bi))\n",
        "            o_t = Activations.sigmoid((self.Wo @ combined.T + self.bo))\n",
        "            c_hat_t = Activations.tanh((self.Wc @ combined.T + self.bc))\n",
        "\n",
        "            f_t = f_t.permute(1,0)\n",
        "            i_t = i_t.permute(1,0)\n",
        "            o_t = o_t.permute(1,0)\n",
        "            c_hat_t = c_hat_t.permute(1,0)\n",
        "\n",
        "            c_t = f_t * c_t + i_t * c_hat_t\n",
        "            h_t = o_t * Activations.tanh(c_t)\n",
        "            h_ts.append(h_t)\n",
        "\n",
        "        return h_t, c_t, h_ts  # Return the final state\n",
        "\n",
        "    def initHidden(self, batch_size=1):\n",
        "        return torch.zeros((batch_size,self.hidden_dim))\n",
        "    def initCellState(self, batch_size=1):\n",
        "        return torch.zeros((batch_size,self.hidden_dim))\n",
        "\n",
        "# Define parameters\n",
        "INPUT_DIM = 10\n",
        "HIDDEN_DIM = 20\n",
        "seq_len = 5\n",
        "batch_size = 64\n",
        "# Create LSTM instance\n",
        "lstm = LSTM(INPUT_DIM, HIDDEN_DIM)\n",
        "\n",
        "# Create dummy input\n",
        "x = torch.randn(batch_size, seq_len, INPUT_DIM)  # (batch_size, sequence_length, input_dim)\n",
        "h0 = lstm.initHidden(batch_size)\n",
        "c0 = lstm.initCellState(batch_size)\n",
        "# combined = np.column_stack((h0, x[:,0,:]))\n",
        "# combined.shape\n",
        "\n",
        "# # Forward propagate\n",
        "h, c, out = lstm.forward(x, h0, c0)\n",
        "# print(\"Last hidden state:\", h)\n"
      ],
      "metadata": {
        "id": "wZr3GqLvgCKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h.shape, c.shape, out[-1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuxnOhDLf_Mg",
        "outputId": "1d1ad811-eaa9-450f-b29a-c82e53326ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 20]), torch.Size([64, 20]), torch.Size([64, 20]))"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7sVlys-hmN5",
        "outputId": "97691b11-64b2-42cb-8878-38e84c6e3ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Rv7ECS5h4iG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}